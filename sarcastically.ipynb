{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "95acebc0",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from common.metrics import f1_m, recall_m, precision_m\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "53c31e86",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   file_name                                          utterance  \\\n0   1_60.wav  It's just a privilege to watch your mind at work.   \n1   1_70.wav  I don't think I'll be able to stop thinking ab...   \n2   1_80.wav  Since it's not bee season, you can have my epi...   \n3   1_90.wav  Lois Lane is falling, accelerating at an initi...   \n4  1_105.wav  I'm just inferring this is a couch because the...   \n\n                                             context  sarcasm  \n0  ['I never would have identified the fingerprin...     True  \n1  ['This is one of my favorite places to kick ba...     True  \n2  ['Here we go. Pad thai, no peanuts.', 'But doe...    False  \n3  ['A marathon? How many Superman movies are the...    False  \n4  [\"Great Caesar's ghost, look at this place.\", ...     True  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>file_name</th>\n      <th>utterance</th>\n      <th>context</th>\n      <th>sarcasm</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1_60.wav</td>\n      <td>It's just a privilege to watch your mind at work.</td>\n      <td>['I never would have identified the fingerprin...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1_70.wav</td>\n      <td>I don't think I'll be able to stop thinking ab...</td>\n      <td>['This is one of my favorite places to kick ba...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1_80.wav</td>\n      <td>Since it's not bee season, you can have my epi...</td>\n      <td>['Here we go. Pad thai, no peanuts.', 'But doe...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1_90.wav</td>\n      <td>Lois Lane is falling, accelerating at an initi...</td>\n      <td>['A marathon? How many Superman movies are the...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1_105.wav</td>\n      <td>I'm just inferring this is a couch because the...</td>\n      <td>[\"Great Caesar's ghost, look at this place.\", ...</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('normalized_mustard_dataset.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "cd25d582",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "embedding_size = 16\n",
    "max_length = 60\n",
    "padding_type = 'post'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d3a752b3",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   file_name                                          utterance  \\\n0   1_60.wav  It's just a privilege to watch your mind at work.   \n1   1_70.wav  I don't think I'll be able to stop thinking ab...   \n2   1_80.wav  Since it's not bee season, you can have my epi...   \n3   1_90.wav  Lois Lane is falling, accelerating at an initi...   \n4  1_105.wav  I'm just inferring this is a couch because the...   \n\n                                             context  sarcasm  \n0  ['I never would have identified the fingerprin...        1  \n1  ['This is one of my favorite places to kick ba...        1  \n2  ['Here we go. Pad thai, no peanuts.', 'But doe...        0  \n3  ['A marathon? How many Superman movies are the...        0  \n4  [\"Great Caesar's ghost, look at this place.\", ...        1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>file_name</th>\n      <th>utterance</th>\n      <th>context</th>\n      <th>sarcasm</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1_60.wav</td>\n      <td>It's just a privilege to watch your mind at work.</td>\n      <td>['I never would have identified the fingerprin...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1_70.wav</td>\n      <td>I don't think I'll be able to stop thinking ab...</td>\n      <td>['This is one of my favorite places to kick ba...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1_80.wav</td>\n      <td>Since it's not bee season, you can have my epi...</td>\n      <td>['Here we go. Pad thai, no peanuts.', 'But doe...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1_90.wav</td>\n      <td>Lois Lane is falling, accelerating at an initi...</td>\n      <td>['A marathon? How many Superman movies are the...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1_105.wav</td>\n      <td>I'm just inferring this is a couch because the...</td>\n      <td>[\"Great Caesar's ghost, look at this place.\", ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sarcasm'].replace({True:1,False:0},inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "dd7bac07",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "utterances = data['utterance'].values\n",
    "sarcasm_states = data['sarcasm'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "49fae700",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(utterances)\n",
    "train = tokenizer.texts_to_sequences(utterances)\n",
    "padded_train_sequences = pad_sequences(train, maxlen=max_length, padding=padding_type)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_text_train = to_categorical(label_encoder.fit_transform(sarcasm_states))\n",
    "\n",
    "vocab_size = len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d08d05bd",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "     file_name                                          utterance  \\\n685  2_169.wav  Hes not right for the part, and if I suggest h...   \n686  2_235.wav  Oh yeah he has a caretaker his older brother, ...   \n687   2_34.wav  Is it me or the greetings gone downhill around...   \n688  2_608.wav  You are right, by saying nice, I am virtually ...   \n689  2_524.wav            Yes and we are \"very\" excited about it.   \n\n                                               context  sarcasm  \n685  ['What am I gonna do now?', 'Just pass the tap...        1  \n686  ['Helo! Anybody in there order a celebrity?', ...        0  \n687                     ['Hey', 'You son of a bitch!']        1  \n688  ['Did I go to this school?', \"Hey, there's Mis...        1  \n689  [\"Anyway, if you don't feel like being alone t...        1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>file_name</th>\n      <th>utterance</th>\n      <th>context</th>\n      <th>sarcasm</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>685</th>\n      <td>2_169.wav</td>\n      <td>Hes not right for the part, and if I suggest h...</td>\n      <td>['What am I gonna do now?', 'Just pass the tap...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>686</th>\n      <td>2_235.wav</td>\n      <td>Oh yeah he has a caretaker his older brother, ...</td>\n      <td>['Helo! Anybody in there order a celebrity?', ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>687</th>\n      <td>2_34.wav</td>\n      <td>Is it me or the greetings gone downhill around...</td>\n      <td>['Hey', 'You son of a bitch!']</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>688</th>\n      <td>2_608.wav</td>\n      <td>You are right, by saying nice, I am virtually ...</td>\n      <td>['Did I go to this school?', \"Hey, there's Mis...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>689</th>\n      <td>2_524.wav</td>\n      <td>Yes and we are \"very\" excited about it.</td>\n      <td>[\"Anyway, if you don't feel like being alone t...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8e82d196",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_text_train, X_text_test, y_text_train, y_text_test = train_test_split(padded_train_sequences, y_text_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f311c624",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "2be61ca8",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_fasttext_vectors2(fname):\n",
    "    embeddings_index = {}\n",
    "    f = codecs.open(fname, encoding='utf-8')\n",
    "    for line in tqdm(f):\n",
    "        values = line.rstrip().rsplit(' ')\n",
    "        ft_word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[ft_word] = coefs\n",
    "    f.close()\n",
    "    return embeddings_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4b3e1fcb",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999995it [01:22, 12147.42it/s]\n"
     ]
    }
   ],
   "source": [
    "w2v_model =  load_fasttext_vectors2(\"wiki-news-300d-1M.vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5b07d323",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Flatten, LSTM, Bidirectional, Conv1D, MaxPooling1D, Input, Embedding\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ec9dc659",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "words_not_found = []\n",
    "nb_words = len(tokenizer.word_index)\n",
    "embedding_matrix = np.zeros((nb_words + 1, 300))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if i >= nb_words:\n",
    "        continue\n",
    "    embedding_vector = w2v_model.get(word)\n",
    "    if (embedding_vector is not None) and len(embedding_vector) > 0:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    else:\n",
    "        words_not_found.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e4028782",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "main_input (InputLayer)      [(None, 60)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 60, 300)           610800    \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 57, 50)            60050     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 28, 50)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 28, 128)           58880     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 3584)              0         \n",
      "_________________________________________________________________\n",
      "fully_connected (Dense)      (None, 75)                268875    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 152       \n",
      "=================================================================\n",
      "Total params: 998,757\n",
      "Trainable params: 387,957\n",
      "Non-trainable params: 610,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_data = Input(shape=(max_length,), name='main_input')\n",
    "embedding_layer = Embedding(vocab_size + 1, 300, weights=[embedding_matrix], trainable=False)(input_data)\n",
    "conv_1 = Conv1D(filters=50, kernel_size=4, activation='relu')(embedding_layer)\n",
    "max_1 = MaxPooling1D(pool_size=2)(conv_1)\n",
    "lstm_layer = Bidirectional(LSTM(64,return_sequences=True))(max_1)\n",
    "\n",
    "flatten = Flatten()(lstm_layer)\n",
    "dense = Dense(75, activation='relu', name='fully_connected')(flatten)\n",
    "out = Dense(2, activation='softmax')(dense)\n",
    "\n",
    "model = Model(inputs=[input_data], outputs=[out])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "abc13eef",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=['accuracy', f1_m, precision_m, recall_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b1bd7fe0",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 552 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-03 02:26:02.482000: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference___backward_cudnn_lstm_with_fallback_49342_49526' and '__inference___backward_standard_lstm_50205_50692_specialized_for_StatefulPartitionedCall_1_at___inference_distributed_function_50969' both implement 'lstm_c87532b8-8a82-4166-8a55-939d8f29c262' but their signatures do not match.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "552/552 [==============================] - 6s 11ms/sample - loss: 0.7030 - accuracy: 0.5109 - f1_m: 0.5115 - precision_m: 0.5115 - recall_m: 0.5115\n",
      "Epoch 2/5\n",
      "552/552 [==============================] - 1s 2ms/sample - loss: 0.6888 - accuracy: 0.5417 - f1_m: 0.5389 - precision_m: 0.5389 - recall_m: 0.5389\n",
      "Epoch 3/5\n",
      "552/552 [==============================] - 1s 2ms/sample - loss: 0.6767 - accuracy: 0.5707 - f1_m: 0.5698 - precision_m: 0.5698 - recall_m: 0.5698\n",
      "Epoch 4/5\n",
      "552/552 [==============================] - 1s 2ms/sample - loss: 0.6453 - accuracy: 0.6250 - f1_m: 0.6240 - precision_m: 0.6240 - recall_m: 0.6240\n",
      "Epoch 5/5\n",
      "552/552 [==============================] - 1s 2ms/sample - loss: 0.5073 - accuracy: 0.7681 - f1_m: 0.7694 - precision_m: 0.7694 - recall_m: 0.7694\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_text_train, y_text_train, batch_size=64, epochs=5, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testing Text Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-03 02:26:13.188909: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference_standard_lstm_51548' and '__inference_standard_lstm_51548_specialized_for_model_2_bidirectional_2_forward_lstm_2_StatefulPartitionedCall_at___inference_distributed_function_52524' both implement 'lstm_1e88a22b-f97a-4950-a32f-7594141cb787' but their signatures do not match.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.7793718602346338\n",
      "accuracy:0.6521739363670349\n",
      "f1_score:0.6862499117851257\n",
      "precision:0.6862500309944153\n",
      "recall:0.6862500309944153\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy, f1_score, precision, recall = model.evaluate(X_text_test, y_text_test, verbose=0)\n",
    "print(f\"loss: {loss}\\naccuracy:{accuracy}\\nf1_score:{f1_score}\\nprecision:{precision}\\nrecall:{recall}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d31ba5bd",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-03 02:26:17.741308: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference_standard_lstm_52818_specialized_for_model_2_bidirectional_2_forward_lstm_2_StatefulPartitionedCall_at___inference_distributed_function_53609' and '__inference_cudnn_lstm_with_fallback_52929' both implement 'lstm_3e93ff0c-1bc2-47ab-b822-8d0d3fe597a7' but their signatures do not match.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-sarcastic\n",
      "[0.7925658  0.20743422]\n"
     ]
    }
   ],
   "source": [
    "user_statement = input(\"Tell me something sarcastic: \\n\")\n",
    "tokenized_statement = tokenizer.texts_to_sequences([user_statement])\n",
    "tokenized_statement = pad_sequences(tokenized_statement, maxlen=max_length, padding=padding_type)\n",
    "output = model.predict(tokenized_statement)[0]\n",
    "\n",
    "if np.argmax(output) == 0:\n",
    "    print(\"Non-sarcastic\")\n",
    "elif np.argmax(output) == 1:\n",
    "    print(\"Sarcasm\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "47fc9839",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.save(\"models/text_model.h5\", overwrite=True, save_format='h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7598d04",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Audio Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a0a54b58",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "40413eef",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "audio_data_fp = \"mmsd_raw_data/converted_utterances\"\n",
    "dataset_csv_path = \"normalized_mustard_dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a460138e",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_mfcc(filepath:str, n_fft:int, hop_length: int, n_mfcc:int = 13):\n",
    "    \"\"\"\n",
    "    Creates MFCC for file at filepath\n",
    "\n",
    "    :param filepath: Location of file to be used\n",
    "    :param n_fft: Number of Fast Fourier Transforms\n",
    "    :param hop_length: Number of Hops within samples\n",
    "    :param n_mfcc: Number of MFCC's to be outputted\n",
    "    :return: Array containing mean of all MFCC's\n",
    "    \"\"\"\n",
    "    signal, sample_rate = librosa.load(filepath)\n",
    "    mfccs = librosa.feature.mfcc(y=signal, sr=sample_rate, n_fft=n_fft, hop_length=hop_length, n_mfcc=n_mfcc)\n",
    "    mean_mfccs = np.mean(mfccs.T,axis=0)\n",
    "    return mean_mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "72a55718",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_mfcc_features(data):\n",
    "    \"\"\"\n",
    "    Creates a list of Mel-Frequency Co-Efficients\n",
    "    :param data: Pandas Dataframe of Input Data\n",
    "    \"\"\"\n",
    "    hop_length = 512\n",
    "    n_fft = 2048\n",
    "\n",
    "    _mfcc_df = pd.DataFrame(columns=[\"features\", \"sarcasm_state\"])\n",
    "\n",
    "    tqdm_data = tqdm(zip(data[\"file_name\"], data[\"sarcasm\"]))\n",
    "\n",
    "    for file_name,sarcasm_state in tqdm_data:\n",
    "        tqdm_data.set_description(f\"Creating MFCC for {file_name}\")\n",
    "        fp = f\"{audio_data_fp}/{str(file_name)}\"\n",
    "        mean_mfccs = create_mfcc(fp, n_fft, hop_length)\n",
    "        _mfcc_df = _mfcc_df.append({\n",
    "            \"features\": mean_mfccs,\n",
    "            \"sarcasm_state\": sarcasm_state\n",
    "        }, ignore_index=True)\n",
    "\n",
    "    return _mfcc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2ad3292f",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating MFCC for 2_524.wav: : 690it [02:44,  4.21it/s]  \n"
     ]
    }
   ],
   "source": [
    "dataset_df = pd.read_csv(dataset_csv_path)\n",
    "mfcc_df = create_mfcc_features(dataset_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "31729dc6",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                            features sarcasm_state\n0  [-146.32887, 99.83219, -50.631638, 9.274939, -...          True\n1  [-147.90367, 104.595116, -39.535, 4.108271, -2...          True\n2  [-21.120022, 86.11223, -35.381474, 22.640253, ...         False\n3  [-23.78374, 70.78856, -34.25742, 23.38274, -16...         False\n4  [1.6350226, 82.73289, -46.96253, 14.140306, -2...          True",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>features</th>\n      <th>sarcasm_state</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[-146.32887, 99.83219, -50.631638, 9.274939, -...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[-147.90367, 104.595116, -39.535, 4.108271, -2...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[-21.120022, 86.11223, -35.381474, 22.640253, ...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[-23.78374, 70.78856, -34.25742, 23.38274, -16...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[1.6350226, 82.73289, -46.96253, 14.140306, -2...</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfcc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4cac8d5e",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = np.array(mfcc_df['features'].tolist())\n",
    "y = np.array(mfcc_df['sarcasm_state'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "acb36ac2",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(690, 13)"
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "364bbd2d",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Label Encoder for getting sarcasm state\n",
    "label_encoder = LabelEncoder()\n",
    "y = to_categorical(label_encoder.fit_transform(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c49dd06f",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(690, 2)"
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c9386d5e",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_audio_train, X_audio_test, y_audio_train, y_audio_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "bcc06f04",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Number of Classes\n",
    "label_count = y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "55034f53",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 100)               1400      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 200)               20200     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 2)                 202       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 41,902\n",
      "Trainable params: 41,902\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(100, input_shape=(13,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(200))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(label_count))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "52c76993",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", metrics=['accuracy',f1_m, precision_m, recall_m], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6d7cb405",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 552 samples\n",
      "Epoch 1/100\n",
      "320/552 [================>.............] - ETA: 0s - loss: 22.1317 - accuracy: 0.4969 - f1_m: 0.4969 - precision_m: 0.4969 - recall_m: 0.4969 WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 1s 2ms/sample - loss: 19.8755 - accuracy: 0.5163 - f1_m: 0.5208 - precision_m: 0.5208 - recall_m: 0.5208\n",
      "Epoch 2/100\n",
      "320/552 [================>.............] - ETA: 0s - loss: 12.9518 - accuracy: 0.5156 - f1_m: 0.5156 - precision_m: 0.5156 - recall_m: 0.5156WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 189us/sample - loss: 12.2448 - accuracy: 0.5181 - f1_m: 0.5174 - precision_m: 0.5174 - recall_m: 0.5174\n",
      "Epoch 3/100\n",
      "320/552 [================>.............] - ETA: 0s - loss: 10.1526 - accuracy: 0.5125 - f1_m: 0.5125 - precision_m: 0.5125 - recall_m: 0.5125WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 199us/sample - loss: 9.7528 - accuracy: 0.5181 - f1_m: 0.5174 - precision_m: 0.5174 - recall_m: 0.5174\n",
      "Epoch 4/100\n",
      "320/552 [================>.............] - ETA: 0s - loss: 6.9520 - accuracy: 0.5281 - f1_m: 0.5281 - precision_m: 0.5281 - recall_m: 0.5281WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 199us/sample - loss: 6.4151 - accuracy: 0.5380 - f1_m: 0.5365 - precision_m: 0.5365 - recall_m: 0.5365\n",
      "Epoch 5/100\n",
      "352/552 [==================>...........] - ETA: 0s - loss: 6.1001 - accuracy: 0.5511 - f1_m: 0.5511 - precision_m: 0.5511 - recall_m: 0.5511WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 192us/sample - loss: 5.6822 - accuracy: 0.5580 - f1_m: 0.5608 - precision_m: 0.5608 - recall_m: 0.5608\n",
      "Epoch 6/100\n",
      "352/552 [==================>...........] - ETA: 0s - loss: 4.4296 - accuracy: 0.5426 - f1_m: 0.5426 - precision_m: 0.5426 - recall_m: 0.5426WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 177us/sample - loss: 4.4887 - accuracy: 0.5507 - f1_m: 0.5538 - precision_m: 0.5538 - recall_m: 0.5538\n",
      "Epoch 7/100\n",
      "352/552 [==================>...........] - ETA: 0s - loss: 4.0470 - accuracy: 0.5312 - f1_m: 0.5312 - precision_m: 0.5312 - recall_m: 0.5312WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 179us/sample - loss: 3.9444 - accuracy: 0.5254 - f1_m: 0.5243 - precision_m: 0.5243 - recall_m: 0.5243\n",
      "Epoch 8/100\n",
      "352/552 [==================>...........] - ETA: 0s - loss: 3.9759 - accuracy: 0.5227 - f1_m: 0.5227 - precision_m: 0.5227 - recall_m: 0.5227WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 184us/sample - loss: 3.7350 - accuracy: 0.5217 - f1_m: 0.5208 - precision_m: 0.5208 - recall_m: 0.5208\n",
      "Epoch 9/100\n",
      "352/552 [==================>...........] - ETA: 0s - loss: 3.0013 - accuracy: 0.5682 - f1_m: 0.5682 - precision_m: 0.5682 - recall_m: 0.5682WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 177us/sample - loss: 2.9396 - accuracy: 0.5525 - f1_m: 0.5608 - precision_m: 0.5608 - recall_m: 0.5608\n",
      "Epoch 10/100\n",
      "320/552 [================>.............] - ETA: 0s - loss: 2.5899 - accuracy: 0.5594 - f1_m: 0.5594 - precision_m: 0.5594 - recall_m: 0.5594WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 193us/sample - loss: 2.3336 - accuracy: 0.5688 - f1_m: 0.5608 - precision_m: 0.5608 - recall_m: 0.5608\n",
      "Epoch 11/100\n",
      "352/552 [==================>...........] - ETA: 0s - loss: 2.2423 - accuracy: 0.5341 - f1_m: 0.5341 - precision_m: 0.5341 - recall_m: 0.5341WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 184us/sample - loss: 2.1427 - accuracy: 0.5362 - f1_m: 0.5347 - precision_m: 0.5347 - recall_m: 0.5347\n",
      "Epoch 12/100\n",
      "352/552 [==================>...........] - ETA: 0s - loss: 1.8298 - accuracy: 0.5653 - f1_m: 0.5653 - precision_m: 0.5653 - recall_m: 0.5653WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 179us/sample - loss: 1.8278 - accuracy: 0.5707 - f1_m: 0.5625 - precision_m: 0.5625 - recall_m: 0.5625\n",
      "Epoch 13/100\n",
      "352/552 [==================>...........] - ETA: 0s - loss: 1.5503 - accuracy: 0.5795 - f1_m: 0.5795 - precision_m: 0.5795 - recall_m: 0.5795WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 177us/sample - loss: 1.5650 - accuracy: 0.5688 - f1_m: 0.5816 - precision_m: 0.5816 - recall_m: 0.5816\n",
      "Epoch 14/100\n",
      "352/552 [==================>...........] - ETA: 0s - loss: 1.5808 - accuracy: 0.4886 - f1_m: 0.4886 - precision_m: 0.4886 - recall_m: 0.4886WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 175us/sample - loss: 1.4902 - accuracy: 0.5290 - f1_m: 0.5434 - precision_m: 0.5434 - recall_m: 0.5434\n",
      "Epoch 15/100\n",
      "352/552 [==================>...........] - ETA: 0s - loss: 1.4867 - accuracy: 0.5398 - f1_m: 0.5398 - precision_m: 0.5398 - recall_m: 0.5398WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 184us/sample - loss: 1.4050 - accuracy: 0.5580 - f1_m: 0.5660 - precision_m: 0.5660 - recall_m: 0.5660\n",
      "Epoch 16/100\n",
      "352/552 [==================>...........] - ETA: 0s - loss: 1.2918 - accuracy: 0.5483 - f1_m: 0.5483 - precision_m: 0.5483 - recall_m: 0.5483WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 180us/sample - loss: 1.2750 - accuracy: 0.5453 - f1_m: 0.5434 - precision_m: 0.5434 - recall_m: 0.5434\n",
      "Epoch 17/100\n",
      "352/552 [==================>...........] - ETA: 0s - loss: 1.2597 - accuracy: 0.5284 - f1_m: 0.5284 - precision_m: 0.5284 - recall_m: 0.5284WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 182us/sample - loss: 1.1681 - accuracy: 0.5308 - f1_m: 0.5191 - precision_m: 0.5191 - recall_m: 0.5191\n",
      "Epoch 18/100\n",
      "352/552 [==================>...........] - ETA: 0s - loss: 1.0954 - accuracy: 0.5511 - f1_m: 0.5511 - precision_m: 0.5511 - recall_m: 0.5511WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 178us/sample - loss: 1.0038 - accuracy: 0.5670 - f1_m: 0.5538 - precision_m: 0.5538 - recall_m: 0.5538\n",
      "Epoch 19/100\n",
      "352/552 [==================>...........] - ETA: 0s - loss: 0.9792 - accuracy: 0.5597 - f1_m: 0.5597 - precision_m: 0.5597 - recall_m: 0.5597WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 178us/sample - loss: 0.9813 - accuracy: 0.5507 - f1_m: 0.5538 - precision_m: 0.5538 - recall_m: 0.5538\n",
      "Epoch 20/100\n",
      "320/552 [================>.............] - ETA: 0s - loss: 0.9750 - accuracy: 0.5844 - f1_m: 0.5844 - precision_m: 0.5844 - recall_m: 0.5844WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 205us/sample - loss: 0.9893 - accuracy: 0.5507 - f1_m: 0.5434 - precision_m: 0.5434 - recall_m: 0.5434\n",
      "Epoch 21/100\n",
      "320/552 [================>.............] - ETA: 0s - loss: 0.9672 - accuracy: 0.5813 - f1_m: 0.5812 - precision_m: 0.5813 - recall_m: 0.5813WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 193us/sample - loss: 0.9403 - accuracy: 0.5779 - f1_m: 0.5747 - precision_m: 0.5747 - recall_m: 0.5747\n",
      "Epoch 22/100\n",
      "352/552 [==================>...........] - ETA: 0s - loss: 0.9256 - accuracy: 0.5767 - f1_m: 0.5767 - precision_m: 0.5767 - recall_m: 0.5767WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 190us/sample - loss: 0.9200 - accuracy: 0.5797 - f1_m: 0.5920 - precision_m: 0.5920 - recall_m: 0.5920\n",
      "Epoch 23/100\n",
      "352/552 [==================>...........] - ETA: 0s - loss: 0.9111 - accuracy: 0.5483 - f1_m: 0.5483 - precision_m: 0.5483 - recall_m: 0.5483WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 189us/sample - loss: 0.9214 - accuracy: 0.5580 - f1_m: 0.5556 - precision_m: 0.5556 - recall_m: 0.5556\n",
      "Epoch 24/100\n",
      "352/552 [==================>...........] - ETA: 0s - loss: 0.7614 - accuracy: 0.5767 - f1_m: 0.5767 - precision_m: 0.5767 - recall_m: 0.5767WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 188us/sample - loss: 0.7926 - accuracy: 0.5725 - f1_m: 0.5747 - precision_m: 0.5747 - recall_m: 0.5747\n",
      "Epoch 25/100\n",
      "352/552 [==================>...........] - ETA: 0s - loss: 0.9195 - accuracy: 0.5199 - f1_m: 0.5199 - precision_m: 0.5199 - recall_m: 0.5199WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 189us/sample - loss: 0.8794 - accuracy: 0.5362 - f1_m: 0.5451 - precision_m: 0.5451 - recall_m: 0.5451\n",
      "Epoch 26/100\n",
      "352/552 [==================>...........] - ETA: 0s - loss: 0.8116 - accuracy: 0.5909 - f1_m: 0.5909 - precision_m: 0.5909 - recall_m: 0.5909WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 187us/sample - loss: 0.7946 - accuracy: 0.5996 - f1_m: 0.6007 - precision_m: 0.6007 - recall_m: 0.6007\n",
      "Epoch 27/100\n",
      "352/552 [==================>...........] - ETA: 0s - loss: 0.7966 - accuracy: 0.5795 - f1_m: 0.5795 - precision_m: 0.5795 - recall_m: 0.5795WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 188us/sample - loss: 0.7970 - accuracy: 0.5833 - f1_m: 0.5851 - precision_m: 0.5851 - recall_m: 0.5851\n",
      "Epoch 28/100\n",
      "352/552 [==================>...........] - ETA: 0s - loss: 0.7273 - accuracy: 0.6080 - f1_m: 0.6080 - precision_m: 0.6080 - recall_m: 0.6080WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 189us/sample - loss: 0.7195 - accuracy: 0.6286 - f1_m: 0.6285 - precision_m: 0.6285 - recall_m: 0.6285\n",
      "Epoch 29/100\n",
      "320/552 [================>.............] - ETA: 0s - loss: 0.7833 - accuracy: 0.6062 - f1_m: 0.6062 - precision_m: 0.6062 - recall_m: 0.6062WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 198us/sample - loss: 0.7899 - accuracy: 0.5924 - f1_m: 0.5937 - precision_m: 0.5938 - recall_m: 0.5938\n",
      "Epoch 30/100\n",
      "352/552 [==================>...........] - ETA: 0s - loss: 0.7908 - accuracy: 0.6222 - f1_m: 0.6222 - precision_m: 0.6222 - recall_m: 0.6222WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 187us/sample - loss: 0.7749 - accuracy: 0.6033 - f1_m: 0.5990 - precision_m: 0.5990 - recall_m: 0.5990\n",
      "Epoch 31/100\n",
      "352/552 [==================>...........] - ETA: 0s - loss: 0.7539 - accuracy: 0.5938 - f1_m: 0.5937 - precision_m: 0.5938 - recall_m: 0.5938WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 188us/sample - loss: 0.7438 - accuracy: 0.5779 - f1_m: 0.5747 - precision_m: 0.5747 - recall_m: 0.5747\n",
      "Epoch 32/100\n",
      "352/552 [==================>...........] - ETA: 0s - loss: 0.8000 - accuracy: 0.5483 - f1_m: 0.5483 - precision_m: 0.5483 - recall_m: 0.5483WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 189us/sample - loss: 0.7568 - accuracy: 0.5707 - f1_m: 0.5677 - precision_m: 0.5677 - recall_m: 0.5677\n",
      "Epoch 33/100\n",
      "320/552 [================>.............] - ETA: 0s - loss: 0.7948 - accuracy: 0.5250 - f1_m: 0.5250 - precision_m: 0.5250 - recall_m: 0.5250WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 189us/sample - loss: 0.7597 - accuracy: 0.5471 - f1_m: 0.5608 - precision_m: 0.5608 - recall_m: 0.5608\n",
      "Epoch 34/100\n",
      "320/552 [================>.............] - ETA: 0s - loss: 0.7389 - accuracy: 0.5437 - f1_m: 0.5437 - precision_m: 0.5437 - recall_m: 0.5437WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 193us/sample - loss: 0.7208 - accuracy: 0.5634 - f1_m: 0.5608 - precision_m: 0.5608 - recall_m: 0.5608\n",
      "Epoch 35/100\n",
      "352/552 [==================>...........] - ETA: 0s - loss: 0.6823 - accuracy: 0.5824 - f1_m: 0.5824 - precision_m: 0.5824 - recall_m: 0.5824WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 188us/sample - loss: 0.6962 - accuracy: 0.5924 - f1_m: 0.5937 - precision_m: 0.5938 - recall_m: 0.5938\n",
      "Epoch 36/100\n",
      "352/552 [==================>...........] - ETA: 0s - loss: 0.6982 - accuracy: 0.6193 - f1_m: 0.6193 - precision_m: 0.6193 - recall_m: 0.6193WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 188us/sample - loss: 0.6937 - accuracy: 0.6033 - f1_m: 0.6042 - precision_m: 0.6042 - recall_m: 0.6042\n",
      "Epoch 37/100\n",
      "320/552 [================>.............] - ETA: 0s - loss: 0.7169 - accuracy: 0.6187 - f1_m: 0.6187 - precision_m: 0.6187 - recall_m: 0.6187WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 190us/sample - loss: 0.7494 - accuracy: 0.5978 - f1_m: 0.5937 - precision_m: 0.5938 - recall_m: 0.5938\n",
      "Epoch 38/100\n",
      "320/552 [================>.............] - ETA: 0s - loss: 0.6961 - accuracy: 0.6094 - f1_m: 0.6094 - precision_m: 0.6094 - recall_m: 0.6094WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 192us/sample - loss: 0.7100 - accuracy: 0.5996 - f1_m: 0.5955 - precision_m: 0.5955 - recall_m: 0.5955\n",
      "Epoch 39/100\n",
      "320/552 [================>.............] - ETA: 0s - loss: 0.7238 - accuracy: 0.5375 - f1_m: 0.5375 - precision_m: 0.5375 - recall_m: 0.5375WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 186us/sample - loss: 0.6890 - accuracy: 0.5797 - f1_m: 0.5764 - precision_m: 0.5764 - recall_m: 0.5764\n",
      "Epoch 40/100\n",
      "352/552 [==================>...........] - ETA: 0s - loss: 0.6829 - accuracy: 0.5966 - f1_m: 0.5966 - precision_m: 0.5966 - recall_m: 0.5966WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 179us/sample - loss: 0.6737 - accuracy: 0.6123 - f1_m: 0.6233 - precision_m: 0.6233 - recall_m: 0.6233\n",
      "Epoch 41/100\n",
      "352/552 [==================>...........] - ETA: 0s - loss: 0.6577 - accuracy: 0.5909 - f1_m: 0.5909 - precision_m: 0.5909 - recall_m: 0.5909WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 177us/sample - loss: 0.6763 - accuracy: 0.5851 - f1_m: 0.5764 - precision_m: 0.5764 - recall_m: 0.5764\n",
      "Epoch 42/100\n",
      "352/552 [==================>...........] - ETA: 0s - loss: 0.6738 - accuracy: 0.6108 - f1_m: 0.6108 - precision_m: 0.6108 - recall_m: 0.6108WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 183us/sample - loss: 0.6761 - accuracy: 0.5888 - f1_m: 0.5903 - precision_m: 0.5903 - recall_m: 0.5903\n",
      "Epoch 43/100\n",
      "352/552 [==================>...........] - ETA: 0s - loss: 0.6753 - accuracy: 0.5994 - f1_m: 0.5994 - precision_m: 0.5994 - recall_m: 0.5994WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 179us/sample - loss: 0.6781 - accuracy: 0.5888 - f1_m: 0.5903 - precision_m: 0.5903 - recall_m: 0.5903\n",
      "Epoch 44/100\n",
      "320/552 [================>.............] - ETA: 0s - loss: 0.7007 - accuracy: 0.6031 - f1_m: 0.6031 - precision_m: 0.6031 - recall_m: 0.6031WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 185us/sample - loss: 0.6843 - accuracy: 0.5960 - f1_m: 0.5972 - precision_m: 0.5972 - recall_m: 0.5972\n",
      "Epoch 45/100\n",
      "352/552 [==================>...........] - ETA: 0s - loss: 0.6617 - accuracy: 0.6023 - f1_m: 0.6023 - precision_m: 0.6023 - recall_m: 0.6023WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 180us/sample - loss: 0.6483 - accuracy: 0.6087 - f1_m: 0.6094 - precision_m: 0.6094 - recall_m: 0.6094\n",
      "Epoch 46/100\n",
      "352/552 [==================>...........] - ETA: 0s - loss: 0.6883 - accuracy: 0.6619 - f1_m: 0.6619 - precision_m: 0.6619 - recall_m: 0.6619WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 181us/sample - loss: 0.6845 - accuracy: 0.6486 - f1_m: 0.6476 - precision_m: 0.6476 - recall_m: 0.6476\n",
      "Epoch 47/100\n",
      "352/552 [==================>...........] - ETA: 0s - loss: 0.6722 - accuracy: 0.6051 - f1_m: 0.6051 - precision_m: 0.6051 - recall_m: 0.6051WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 184us/sample - loss: 0.6780 - accuracy: 0.6123 - f1_m: 0.6076 - precision_m: 0.6076 - recall_m: 0.6076\n",
      "Epoch 48/100\n",
      "352/552 [==================>...........] - ETA: 0s - loss: 0.6367 - accuracy: 0.6420 - f1_m: 0.6420 - precision_m: 0.6420 - recall_m: 0.6420WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 179us/sample - loss: 0.6492 - accuracy: 0.6123 - f1_m: 0.6128 - precision_m: 0.6128 - recall_m: 0.6128\n",
      "Epoch 49/100\n",
      "320/552 [================>.............] - ETA: 0s - loss: 0.6924 - accuracy: 0.5813 - f1_m: 0.5812 - precision_m: 0.5813 - recall_m: 0.5813WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 183us/sample - loss: 0.6730 - accuracy: 0.5924 - f1_m: 0.5990 - precision_m: 0.5990 - recall_m: 0.5990\n",
      "Epoch 50/100\n",
      "352/552 [==================>...........] - ETA: 0s - loss: 0.6462 - accuracy: 0.6420 - f1_m: 0.6420 - precision_m: 0.6420 - recall_m: 0.6420WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 182us/sample - loss: 0.6595 - accuracy: 0.6105 - f1_m: 0.6111 - precision_m: 0.6111 - recall_m: 0.6111\n",
      "Epoch 51/100\n",
      "352/552 [==================>...........] - ETA: 0s - loss: 0.6802 - accuracy: 0.6562 - f1_m: 0.6562 - precision_m: 0.6562 - recall_m: 0.6562WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 183us/sample - loss: 0.6765 - accuracy: 0.6413 - f1_m: 0.6354 - precision_m: 0.6354 - recall_m: 0.6354\n",
      "Epoch 52/100\n",
      "352/552 [==================>...........] - ETA: 0s - loss: 0.6880 - accuracy: 0.6136 - f1_m: 0.6136 - precision_m: 0.6136 - recall_m: 0.6136WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 183us/sample - loss: 0.7084 - accuracy: 0.5978 - f1_m: 0.5990 - precision_m: 0.5990 - recall_m: 0.5990\n",
      "Epoch 53/100\n",
      "352/552 [==================>...........] - ETA: 0s - loss: 0.6325 - accuracy: 0.6080 - f1_m: 0.6080 - precision_m: 0.6080 - recall_m: 0.6080WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 182us/sample - loss: 0.6497 - accuracy: 0.6014 - f1_m: 0.6076 - precision_m: 0.6076 - recall_m: 0.6076\n",
      "Epoch 54/100\n",
      "320/552 [================>.............] - ETA: 0s - loss: 0.6760 - accuracy: 0.5969 - f1_m: 0.5969 - precision_m: 0.5969 - recall_m: 0.5969WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 194us/sample - loss: 0.6625 - accuracy: 0.5996 - f1_m: 0.6059 - precision_m: 0.6059 - recall_m: 0.6059\n",
      "Epoch 55/100\n",
      "352/552 [==================>...........] - ETA: 0s - loss: 0.6373 - accuracy: 0.6136 - f1_m: 0.6136 - precision_m: 0.6136 - recall_m: 0.6136WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 187us/sample - loss: 0.6425 - accuracy: 0.6105 - f1_m: 0.6111 - precision_m: 0.6111 - recall_m: 0.6111\n",
      "Epoch 56/100\n",
      "352/552 [==================>...........] - ETA: 0s - loss: 0.6464 - accuracy: 0.6392 - f1_m: 0.6392 - precision_m: 0.6392 - recall_m: 0.6392WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 185us/sample - loss: 0.6408 - accuracy: 0.6232 - f1_m: 0.6337 - precision_m: 0.6337 - recall_m: 0.6337\n",
      "Epoch 57/100\n",
      "352/552 [==================>...........] - ETA: 0s - loss: 0.6651 - accuracy: 0.6193 - f1_m: 0.6193 - precision_m: 0.6193 - recall_m: 0.6193WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 189us/sample - loss: 0.6567 - accuracy: 0.6322 - f1_m: 0.6319 - precision_m: 0.6319 - recall_m: 0.6319\n",
      "Epoch 58/100\n",
      "320/552 [================>.............] - ETA: 0s - loss: 0.6812 - accuracy: 0.6125 - f1_m: 0.6125 - precision_m: 0.6125 - recall_m: 0.6125WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 194us/sample - loss: 0.6547 - accuracy: 0.6123 - f1_m: 0.6076 - precision_m: 0.6076 - recall_m: 0.6076\n",
      "Epoch 59/100\n",
      "320/552 [================>.............] - ETA: 0s - loss: 0.6116 - accuracy: 0.6438 - f1_m: 0.6437 - precision_m: 0.6438 - recall_m: 0.6438WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 193us/sample - loss: 0.6295 - accuracy: 0.6359 - f1_m: 0.6406 - precision_m: 0.6406 - recall_m: 0.6406\n",
      "Epoch 60/100\n",
      "320/552 [================>.............] - ETA: 0s - loss: 0.6238 - accuracy: 0.6469 - f1_m: 0.6469 - precision_m: 0.6469 - recall_m: 0.6469WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 192us/sample - loss: 0.6458 - accuracy: 0.6196 - f1_m: 0.6094 - precision_m: 0.6094 - recall_m: 0.6094\n",
      "Epoch 61/100\n",
      "320/552 [================>.............] - ETA: 0s - loss: 0.6567 - accuracy: 0.6156 - f1_m: 0.6156 - precision_m: 0.6156 - recall_m: 0.6156WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 192us/sample - loss: 0.6477 - accuracy: 0.6250 - f1_m: 0.6198 - precision_m: 0.6198 - recall_m: 0.6198\n",
      "Epoch 62/100\n",
      "320/552 [================>.............] - ETA: 0s - loss: 0.6231 - accuracy: 0.6250 - f1_m: 0.6250 - precision_m: 0.6250 - recall_m: 0.6250WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 197us/sample - loss: 0.6485 - accuracy: 0.5978 - f1_m: 0.5990 - precision_m: 0.5990 - recall_m: 0.5990\n",
      "Epoch 63/100\n",
      "320/552 [================>.............] - ETA: 0s - loss: 0.6384 - accuracy: 0.6750 - f1_m: 0.6750 - precision_m: 0.6750 - recall_m: 0.6750WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 205us/sample - loss: 0.6387 - accuracy: 0.6721 - f1_m: 0.6858 - precision_m: 0.6858 - recall_m: 0.6858\n",
      "Epoch 64/100\n",
      "320/552 [================>.............] - ETA: 0s - loss: 0.6364 - accuracy: 0.6406 - f1_m: 0.6406 - precision_m: 0.6406 - recall_m: 0.6406WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 196us/sample - loss: 0.6312 - accuracy: 0.6286 - f1_m: 0.6285 - precision_m: 0.6285 - recall_m: 0.6285\n",
      "Epoch 65/100\n",
      "320/552 [================>.............] - ETA: 0s - loss: 0.6401 - accuracy: 0.6375 - f1_m: 0.6375 - precision_m: 0.6375 - recall_m: 0.6375WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 199us/sample - loss: 0.6461 - accuracy: 0.6286 - f1_m: 0.6285 - precision_m: 0.6285 - recall_m: 0.6285\n",
      "Epoch 66/100\n",
      "320/552 [================>.............] - ETA: 0s - loss: 0.6268 - accuracy: 0.6438 - f1_m: 0.6437 - precision_m: 0.6438 - recall_m: 0.6438WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 201us/sample - loss: 0.6274 - accuracy: 0.6341 - f1_m: 0.6337 - precision_m: 0.6337 - recall_m: 0.6337\n",
      "Epoch 67/100\n",
      "320/552 [================>.............] - ETA: 0s - loss: 0.6360 - accuracy: 0.6438 - f1_m: 0.6437 - precision_m: 0.6438 - recall_m: 0.6438WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 207us/sample - loss: 0.6420 - accuracy: 0.6467 - f1_m: 0.6354 - precision_m: 0.6354 - recall_m: 0.6354\n",
      "Epoch 68/100\n",
      "320/552 [================>.............] - ETA: 0s - loss: 0.6447 - accuracy: 0.6281 - f1_m: 0.6281 - precision_m: 0.6281 - recall_m: 0.6281WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 204us/sample - loss: 0.6396 - accuracy: 0.6214 - f1_m: 0.6163 - precision_m: 0.6163 - recall_m: 0.6163\n",
      "Epoch 69/100\n",
      "320/552 [================>.............] - ETA: 0s - loss: 0.6095 - accuracy: 0.6625 - f1_m: 0.6625 - precision_m: 0.6625 - recall_m: 0.6625WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 207us/sample - loss: 0.6355 - accuracy: 0.6395 - f1_m: 0.6389 - precision_m: 0.6389 - recall_m: 0.6389\n",
      "Epoch 70/100\n",
      "320/552 [================>.............] - ETA: 0s - loss: 0.6465 - accuracy: 0.6469 - f1_m: 0.6469 - precision_m: 0.6469 - recall_m: 0.6469WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 209us/sample - loss: 0.6353 - accuracy: 0.6612 - f1_m: 0.6545 - precision_m: 0.6545 - recall_m: 0.6545\n",
      "Epoch 71/100\n",
      "320/552 [================>.............] - ETA: 0s - loss: 0.6089 - accuracy: 0.6625 - f1_m: 0.6625 - precision_m: 0.6625 - recall_m: 0.6625WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 209us/sample - loss: 0.6220 - accuracy: 0.6304 - f1_m: 0.6302 - precision_m: 0.6302 - recall_m: 0.6302\n",
      "Epoch 72/100\n",
      "288/552 [==============>...............] - ETA: 0s - loss: 0.6843 - accuracy: 0.6007 - f1_m: 0.6007 - precision_m: 0.6007 - recall_m: 0.6007WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 218us/sample - loss: 0.6522 - accuracy: 0.6341 - f1_m: 0.6389 - precision_m: 0.6389 - recall_m: 0.6389\n",
      "Epoch 73/100\n",
      "320/552 [================>.............] - ETA: 0s - loss: 0.6376 - accuracy: 0.6344 - f1_m: 0.6344 - precision_m: 0.6344 - recall_m: 0.6344WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 209us/sample - loss: 0.6475 - accuracy: 0.6214 - f1_m: 0.6267 - precision_m: 0.6267 - recall_m: 0.6267\n",
      "Epoch 74/100\n",
      "320/552 [================>.............] - ETA: 0s - loss: 0.6634 - accuracy: 0.5938 - f1_m: 0.5937 - precision_m: 0.5938 - recall_m: 0.5938WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 210us/sample - loss: 0.6586 - accuracy: 0.6087 - f1_m: 0.6146 - precision_m: 0.6146 - recall_m: 0.6146\n",
      "Epoch 75/100\n",
      "320/552 [================>.............] - ETA: 0s - loss: 0.6448 - accuracy: 0.6187 - f1_m: 0.6187 - precision_m: 0.6187 - recall_m: 0.6187WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 212us/sample - loss: 0.6354 - accuracy: 0.6377 - f1_m: 0.6424 - precision_m: 0.6424 - recall_m: 0.6424\n",
      "Epoch 76/100\n",
      "544/552 [============================>.] - ETA: 0s - loss: 0.6201 - accuracy: 0.6507 - f1_m: 0.6507 - precision_m: 0.6507 - recall_m: 0.6507WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 230us/sample - loss: 0.6173 - accuracy: 0.6540 - f1_m: 0.6632 - precision_m: 0.6632 - recall_m: 0.6632\n",
      "Epoch 77/100\n",
      "544/552 [============================>.] - ETA: 0s - loss: 0.6302 - accuracy: 0.6544 - f1_m: 0.6544 - precision_m: 0.6544 - recall_m: 0.6544WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 223us/sample - loss: 0.6292 - accuracy: 0.6558 - f1_m: 0.6597 - precision_m: 0.6597 - recall_m: 0.6597\n",
      "Epoch 78/100\n",
      "544/552 [============================>.] - ETA: 0s - loss: 0.6050 - accuracy: 0.6452 - f1_m: 0.6452 - precision_m: 0.6452 - recall_m: 0.6452WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 221us/sample - loss: 0.6049 - accuracy: 0.6467 - f1_m: 0.6510 - precision_m: 0.6510 - recall_m: 0.6510\n",
      "Epoch 79/100\n",
      "544/552 [============================>.] - ETA: 0s - loss: 0.6220 - accuracy: 0.6287 - f1_m: 0.6287 - precision_m: 0.6287 - recall_m: 0.6287WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 224us/sample - loss: 0.6191 - accuracy: 0.6304 - f1_m: 0.6354 - precision_m: 0.6354 - recall_m: 0.6354\n",
      "Epoch 80/100\n",
      "544/552 [============================>.] - ETA: 0s - loss: 0.6506 - accuracy: 0.6434 - f1_m: 0.6434 - precision_m: 0.6434 - recall_m: 0.6434WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 236us/sample - loss: 0.6503 - accuracy: 0.6413 - f1_m: 0.6354 - precision_m: 0.6354 - recall_m: 0.6354\n",
      "Epoch 81/100\n",
      "544/552 [============================>.] - ETA: 0s - loss: 0.6223 - accuracy: 0.6489 - f1_m: 0.6489 - precision_m: 0.6489 - recall_m: 0.6489WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 233us/sample - loss: 0.6228 - accuracy: 0.6467 - f1_m: 0.6406 - precision_m: 0.6406 - recall_m: 0.6406\n",
      "Epoch 82/100\n",
      "544/552 [============================>.] - ETA: 0s - loss: 0.6208 - accuracy: 0.6526 - f1_m: 0.6526 - precision_m: 0.6526 - recall_m: 0.6526WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 237us/sample - loss: 0.6283 - accuracy: 0.6486 - f1_m: 0.6372 - precision_m: 0.6372 - recall_m: 0.6372\n",
      "Epoch 83/100\n",
      "544/552 [============================>.] - ETA: 0s - loss: 0.6268 - accuracy: 0.6379 - f1_m: 0.6379 - precision_m: 0.6379 - recall_m: 0.6379WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 234us/sample - loss: 0.6245 - accuracy: 0.6413 - f1_m: 0.6510 - precision_m: 0.6510 - recall_m: 0.6510\n",
      "Epoch 84/100\n",
      "480/552 [=========================>....] - ETA: 0s - loss: 0.6320 - accuracy: 0.6458 - f1_m: 0.6458 - precision_m: 0.6458 - recall_m: 0.6458WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 259us/sample - loss: 0.6274 - accuracy: 0.6504 - f1_m: 0.6545 - precision_m: 0.6545 - recall_m: 0.6545\n",
      "Epoch 85/100\n",
      "480/552 [=========================>....] - ETA: 0s - loss: 0.6081 - accuracy: 0.6542 - f1_m: 0.6542 - precision_m: 0.6542 - recall_m: 0.6542WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 253us/sample - loss: 0.6292 - accuracy: 0.6486 - f1_m: 0.6580 - precision_m: 0.6580 - recall_m: 0.6580\n",
      "Epoch 86/100\n",
      "480/552 [=========================>....] - ETA: 0s - loss: 0.6472 - accuracy: 0.6062 - f1_m: 0.6062 - precision_m: 0.6062 - recall_m: 0.6062WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 254us/sample - loss: 0.6493 - accuracy: 0.6069 - f1_m: 0.6181 - precision_m: 0.6181 - recall_m: 0.6181\n",
      "Epoch 87/100\n",
      "480/552 [=========================>....] - ETA: 0s - loss: 0.6332 - accuracy: 0.6313 - f1_m: 0.6312 - precision_m: 0.6313 - recall_m: 0.6313WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 258us/sample - loss: 0.6319 - accuracy: 0.6304 - f1_m: 0.6302 - precision_m: 0.6302 - recall_m: 0.6302\n",
      "Epoch 88/100\n",
      "480/552 [=========================>....] - ETA: 0s - loss: 0.6277 - accuracy: 0.6292 - f1_m: 0.6292 - precision_m: 0.6292 - recall_m: 0.6292WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 253us/sample - loss: 0.6400 - accuracy: 0.6178 - f1_m: 0.6128 - precision_m: 0.6128 - recall_m: 0.6128\n",
      "Epoch 89/100\n",
      "480/552 [=========================>....] - ETA: 0s - loss: 0.6452 - accuracy: 0.6313 - f1_m: 0.6312 - precision_m: 0.6313 - recall_m: 0.6313WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 257us/sample - loss: 0.6421 - accuracy: 0.6359 - f1_m: 0.6406 - precision_m: 0.6406 - recall_m: 0.6406\n",
      "Epoch 90/100\n",
      "480/552 [=========================>....] - ETA: 0s - loss: 0.6342 - accuracy: 0.6458 - f1_m: 0.6458 - precision_m: 0.6458 - recall_m: 0.6458WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 258us/sample - loss: 0.6238 - accuracy: 0.6576 - f1_m: 0.6667 - precision_m: 0.6667 - recall_m: 0.6667\n",
      "Epoch 91/100\n",
      "480/552 [=========================>....] - ETA: 0s - loss: 0.6229 - accuracy: 0.6562 - f1_m: 0.6562 - precision_m: 0.6562 - recall_m: 0.6562WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 265us/sample - loss: 0.6205 - accuracy: 0.6467 - f1_m: 0.6406 - precision_m: 0.6406 - recall_m: 0.6406\n",
      "Epoch 92/100\n",
      "480/552 [=========================>....] - ETA: 0s - loss: 0.6135 - accuracy: 0.6479 - f1_m: 0.6479 - precision_m: 0.6479 - recall_m: 0.6479WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 263us/sample - loss: 0.6342 - accuracy: 0.6286 - f1_m: 0.6233 - precision_m: 0.6233 - recall_m: 0.6233\n",
      "Epoch 93/100\n",
      "480/552 [=========================>....] - ETA: 0s - loss: 0.6272 - accuracy: 0.6354 - f1_m: 0.6354 - precision_m: 0.6354 - recall_m: 0.6354WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 265us/sample - loss: 0.6258 - accuracy: 0.6322 - f1_m: 0.6215 - precision_m: 0.6215 - recall_m: 0.6215\n",
      "Epoch 94/100\n",
      "480/552 [=========================>....] - ETA: 0s - loss: 0.6085 - accuracy: 0.6687 - f1_m: 0.6687 - precision_m: 0.6687 - recall_m: 0.6687WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 268us/sample - loss: 0.6137 - accuracy: 0.6612 - f1_m: 0.6597 - precision_m: 0.6597 - recall_m: 0.6597\n",
      "Epoch 95/100\n",
      "480/552 [=========================>....] - ETA: 0s - loss: 0.6259 - accuracy: 0.6438 - f1_m: 0.6437 - precision_m: 0.6438 - recall_m: 0.6438WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 264us/sample - loss: 0.6272 - accuracy: 0.6522 - f1_m: 0.6510 - precision_m: 0.6510 - recall_m: 0.6510\n",
      "Epoch 96/100\n",
      "480/552 [=========================>....] - ETA: 0s - loss: 0.6026 - accuracy: 0.6604 - f1_m: 0.6604 - precision_m: 0.6604 - recall_m: 0.6604WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 270us/sample - loss: 0.6110 - accuracy: 0.6576 - f1_m: 0.6562 - precision_m: 0.6562 - recall_m: 0.6562\n",
      "Epoch 97/100\n",
      "480/552 [=========================>....] - ETA: 0s - loss: 0.6213 - accuracy: 0.6750 - f1_m: 0.6750 - precision_m: 0.6750 - recall_m: 0.6750WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 265us/sample - loss: 0.6305 - accuracy: 0.6685 - f1_m: 0.6615 - precision_m: 0.6615 - recall_m: 0.6615\n",
      "Epoch 98/100\n",
      "480/552 [=========================>....] - ETA: 0s - loss: 0.6505 - accuracy: 0.6292 - f1_m: 0.6292 - precision_m: 0.6292 - recall_m: 0.6292WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 272us/sample - loss: 0.6428 - accuracy: 0.6322 - f1_m: 0.6215 - precision_m: 0.6215 - recall_m: 0.6215\n",
      "Epoch 99/100\n",
      "448/552 [=======================>......] - ETA: 0s - loss: 0.6371 - accuracy: 0.6183 - f1_m: 0.6183 - precision_m: 0.6183 - recall_m: 0.6183WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 326us/sample - loss: 0.6315 - accuracy: 0.6286 - f1_m: 0.6233 - precision_m: 0.6233 - recall_m: 0.6233\n",
      "Epoch 100/100\n",
      "416/552 [=====================>........] - ETA: 0s - loss: 0.6010 - accuracy: 0.6466 - f1_m: 0.6466 - precision_m: 0.6466 - recall_m: 0.6466WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "552/552 [==============================] - 0s 314us/sample - loss: 0.6031 - accuracy: 0.6395 - f1_m: 0.6441 - precision_m: 0.6441 - recall_m: 0.6441\n"
     ]
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7fe00cea9690>"
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "num_batch_size = 32\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=\"../models/audio_model.h5\", verbose=True, save_best_only=True)\n",
    "\n",
    "model.fit(X_audio_train, y_audio_train, batch_size=num_batch_size, epochs=num_epochs, callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4baa0dfd",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Audio Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2355a877",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.5907537319521973\n",
      "accuracy:0.6594203114509583\n",
      "f1_score:0.6787499189376831\n",
      "precision:0.6787499785423279\n",
      "recall:0.6787499785423279\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy, f1_score, precision, recall = model.evaluate(X_audio_test, y_audio_test, verbose=0)\n",
    "print(f\"loss: {loss}\\naccuracy:{accuracy}\\nf1_score:{f1_score}\\nprecision:{precision}\\nrecall:{recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "31bd5b74",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_file_path = \"mmsd_raw_data/converted_utterances/2_626.wav\"\n",
    "audio, sample_rate = librosa.load(test_file_path)\n",
    "mfcc_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=13)\n",
    "mfcc_scaled_features = np.mean(mfcc_features.T, axis=0)\n",
    "\n",
    "mfcc_scaled_features = mfcc_scaled_features.reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "83c2dea3",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sarcastic: 1\n",
      "[[2.7844343e-21 1.0000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "predicted_label = model.predict_classes(mfcc_scaled_features)\n",
    "predicted_class = label_encoder.inverse_transform(predicted_label)\n",
    "print(f\"Sarcastic: {predicted_class[0]}\")\n",
    "\n",
    "x = model.predict_proba(mfcc_scaled_features)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75257a76",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Aggregator Model"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 132,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "outputs": [],
   "source": [
    "models_dir = \"models\"\n",
    "\n",
    "text_model = load_model(f\"{models_dir}/text_model.h5\")\n",
    "audio_model = load_model(f\"{models_dir}/audio_model.h5\")\n",
    "\n",
    "file_lookup_index = 686\n",
    "text_model_weight = .195\n",
    "audio_model_weight = 1 - text_model_weight"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "outputs": [],
   "source": [
    "testd_token_statement = tokenizer.texts_to_sequences([data['utterance'][file_lookup_index]])\n",
    "testd_token_statement = pad_sequences(testd_token_statement, maxlen=max_length, padding=padding_type)\n",
    "testd_output = text_model.predict(tokenized_statement)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "outputs": [],
   "source": [
    "testd_file_path = f\"mmsd_raw_data/converted_utterances/{data['file_name'][file_lookup_index]}\"\n",
    "testd_audio, testd_sample_rate = librosa.load(testd_file_path)\n",
    "testd_mfcc_features = librosa.feature.mfcc(y=testd_audio, sr=testd_sample_rate, n_mfcc=13)\n",
    "testd_mfcc_scaled_features = np.mean(testd_mfcc_features.T, axis=0)\n",
    "testd_mfcc_scaled_features = testd_mfcc_scaled_features.reshape(1, -1)\n",
    "testd_predicted_label = audio_model.predict(testd_mfcc_scaled_features)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Name: 2_235.wav\n",
      "Utterance: Oh yeah he has a caretaker his older brother, Ernie. You can't make this stuff up!\n",
      "Sarcastic: 0\n",
      "Text Prediction [[0.92711174 0.07288828]]\n",
      "Audio Prediction [[0.24476345 0.7552366 ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"File Name:\",data['file_name'][file_lookup_index])\n",
    "print(\"Utterance:\",data['utterance'][file_lookup_index])\n",
    "print(\"Sarcastic:\",data['sarcasm'][file_lookup_index])\n",
    "print(\"Text Prediction\", testd_output)\n",
    "print(\"Audio Prediction\", testd_predicted_label)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "outputs": [
    {
     "data": {
      "text/plain": "0.37782136656343934"
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_0 = (testd_predicted_label[0][0]*audio_model_weight + testd_output[0][0]*text_model_weight)\n",
    "total_0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "outputs": [
    {
     "data": {
      "text/plain": "0.622178697772324"
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_1 = (testd_predicted_label[0][1]*audio_model_weight + testd_output[0][1]*text_model_weight)\n",
    "total_1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sarcastic\n"
     ]
    }
   ],
   "source": [
    "total = total_0 - total_1\n",
    "\n",
    "if total <= 0:\n",
    "    print(\"Sarcastic\")\n",
    "else:\n",
    "    print(\"Non Sarcastic\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
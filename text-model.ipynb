{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "                                           utterance  speaker  \\\n0  It's just a privilege to watch your mind at work.  SHELDON   \n1  I don't think I'll be able to stop thinking ab...    PENNY   \n2  Since it's not bee season, you can have my epi...  SHELDON   \n3  Lois Lane is falling, accelerating at an initi...  SHELDON   \n4  I'm just inferring this is a couch because the...  SHELDON   \n\n                                             context  \\\n0  ['I never would have identified the fingerprin...   \n1  ['This is one of my favorite places to kick ba...   \n2  ['Here we go. Pad thai, no peanuts.', 'But doe...   \n3  ['A marathon? How many Superman movies are the...   \n4  [\"Great Caesar's ghost, look at this place.\", ...   \n\n                                    context_speakers show  sarcasm  \n0                             ['LEONARD', 'SHELDON']  BBT     True  \n1  ['HOWARD', 'PENNY', 'HOWARD', 'HOWARD', 'HOWAR...  BBT     True  \n2                   ['LEONARD', 'HOWARD', 'LEONARD']  BBT    False  \n3  ['PENNY', 'SHELDON', 'PENNY', 'SHELDON', 'SHEL...  BBT    False  \n4  ['SHELDON', 'LEONARD', 'SHELDON', 'SHELDON', '...  BBT     True  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>utterance</th>\n      <th>speaker</th>\n      <th>context</th>\n      <th>context_speakers</th>\n      <th>show</th>\n      <th>sarcasm</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>It's just a privilege to watch your mind at work.</td>\n      <td>SHELDON</td>\n      <td>['I never would have identified the fingerprin...</td>\n      <td>['LEONARD', 'SHELDON']</td>\n      <td>BBT</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>I don't think I'll be able to stop thinking ab...</td>\n      <td>PENNY</td>\n      <td>['This is one of my favorite places to kick ba...</td>\n      <td>['HOWARD', 'PENNY', 'HOWARD', 'HOWARD', 'HOWAR...</td>\n      <td>BBT</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Since it's not bee season, you can have my epi...</td>\n      <td>SHELDON</td>\n      <td>['Here we go. Pad thai, no peanuts.', 'But doe...</td>\n      <td>['LEONARD', 'HOWARD', 'LEONARD']</td>\n      <td>BBT</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Lois Lane is falling, accelerating at an initi...</td>\n      <td>SHELDON</td>\n      <td>['A marathon? How many Superman movies are the...</td>\n      <td>['PENNY', 'SHELDON', 'PENNY', 'SHELDON', 'SHEL...</td>\n      <td>BBT</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I'm just inferring this is a couch because the...</td>\n      <td>SHELDON</td>\n      <td>[\"Great Caesar's ghost, look at this place.\", ...</td>\n      <td>['SHELDON', 'LEONARD', 'SHELDON', 'SHELDON', '...</td>\n      <td>BBT</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('normalized_mustard_dataset.csv')\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'scipy.sparse.csr.csr_matrix'>, <class 'NoneType'>\n",
      "Train on 517 samples, validate on 173 samples\n",
      "Epoch 1/10\n",
      "517/517 [==============================] - 1s 3ms/sample - loss: 0.6978 - accuracy: 0.5106 - val_loss: 0.6933 - val_accuracy: 0.4682\n",
      "Epoch 2/10\n",
      "517/517 [==============================] - 1s 1ms/sample - loss: 0.6931 - accuracy: 0.5106 - val_loss: 0.6934 - val_accuracy: 0.4682\n",
      "Epoch 3/10\n",
      "517/517 [==============================] - 1s 1ms/sample - loss: 0.6931 - accuracy: 0.5106 - val_loss: 0.6934 - val_accuracy: 0.4682\n",
      "Epoch 4/10\n",
      "517/517 [==============================] - 1s 1ms/sample - loss: 0.6931 - accuracy: 0.5106 - val_loss: 0.6934 - val_accuracy: 0.4682\n",
      "Epoch 5/10\n",
      "517/517 [==============================] - 1s 1ms/sample - loss: 0.6931 - accuracy: 0.5106 - val_loss: 0.6933 - val_accuracy: 0.4682\n",
      "Epoch 6/10\n",
      "517/517 [==============================] - 1s 1ms/sample - loss: 0.6931 - accuracy: 0.5106 - val_loss: 0.6934 - val_accuracy: 0.4682\n",
      "Epoch 7/10\n",
      "517/517 [==============================] - 1s 1ms/sample - loss: 0.6931 - accuracy: 0.5106 - val_loss: 0.6934 - val_accuracy: 0.4682\n",
      "Epoch 8/10\n",
      "517/517 [==============================] - 1s 1ms/sample - loss: 0.6931 - accuracy: 0.5106 - val_loss: 0.6934 - val_accuracy: 0.4682\n",
      "Epoch 9/10\n",
      "517/517 [==============================] - 1s 1ms/sample - loss: 0.6931 - accuracy: 0.5106 - val_loss: 0.6935 - val_accuracy: 0.4682\n",
      "Epoch 10/10\n",
      "517/517 [==============================] - 1s 1ms/sample - loss: 0.6931 - accuracy: 0.5106 - val_loss: 0.6935 - val_accuracy: 0.4682\n"
     ]
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7fbd3f4c6fd0>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = 10000\n",
    "embedding_size = 16\n",
    "required_data = data[['utterance', 'sarcasm']]\n",
    "\n",
    "utterances = np.array(required_data['utterance'])\n",
    "utterance_list = utterances.tolist()\n",
    "sarcasm_states = np.array(required_data['sarcasm'])\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "X1 = tfidf.fit_transform(utterance_list)\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(X1,sarcasm_states, test_size=0.25)\n",
    "# model = BernoulliNB()\n",
    "# model.fit(x_train, y_train)\n",
    "# print(model.score(x_test,y_test))\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_size, input_length=1977),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(6, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, np.array(y_train), epochs=10, validation_data=(x_test, np.array(y_test)))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/yr/bypblhs13dn152ph6rl99d300000gn/T/ipykernel_26772/4274199563.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0muser_statement\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Tell me something sarcastic: \\n\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;31m# data = tfidf.transform([user_statement]).toarray()\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0moutput\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0muser_statement\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moutput\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/ds/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001B[0m in \u001B[0;36mpredict\u001B[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m    907\u001B[0m         \u001B[0mmax_queue_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmax_queue_size\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    908\u001B[0m         \u001B[0mworkers\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mworkers\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 909\u001B[0;31m         use_multiprocessing=use_multiprocessing)\n\u001B[0m\u001B[1;32m    910\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    911\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0mreset_metrics\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/ds/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001B[0m in \u001B[0;36mpredict\u001B[0;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001B[0m\n\u001B[1;32m    460\u001B[0m     return self._model_iteration(\n\u001B[1;32m    461\u001B[0m         \u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mModeKeys\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mPREDICT\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mverbose\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 462\u001B[0;31m         steps=steps, callbacks=callbacks, **kwargs)\n\u001B[0m\u001B[1;32m    463\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    464\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/ds/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001B[0m in \u001B[0;36m_model_iteration\u001B[0;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, **kwargs)\u001B[0m\n\u001B[1;32m    394\u001B[0m           \u001B[0msample_weights\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0msample_weight\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    395\u001B[0m           \u001B[0msteps\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0msteps\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 396\u001B[0;31m           distribution_strategy=strategy)\n\u001B[0m\u001B[1;32m    397\u001B[0m       \u001B[0mtotal_samples\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_get_total_number_of_samples\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0madapter\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    398\u001B[0m       \u001B[0muse_sample\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtotal_samples\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/ds/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001B[0m in \u001B[0;36m_process_inputs\u001B[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m    604\u001B[0m       \u001B[0mmax_queue_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmax_queue_size\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    605\u001B[0m       \u001B[0mworkers\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mworkers\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 606\u001B[0;31m       use_multiprocessing=use_multiprocessing)\n\u001B[0m\u001B[1;32m    607\u001B[0m   \u001B[0;31m# As a fallback for the data type that does not work with\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    608\u001B[0m   \u001B[0;31m# _standardize_user_data, use the _prepare_model_with_inputs.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/ds/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/data_adapter.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, x, y, sample_weights, batch_size, shuffle, **kwargs)\u001B[0m\n\u001B[1;32m    477\u001B[0m     self._internal_adapter = TensorLikeDataAdapter(\n\u001B[1;32m    478\u001B[0m         \u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msample_weights\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0msample_weights\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 479\u001B[0;31m         batch_size=batch_size, shuffle=shuffle, **kwargs)\n\u001B[0m\u001B[1;32m    480\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    481\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0mget_dataset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/ds/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/data_adapter.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, x, y, sample_weights, batch_size, epochs, steps, shuffle, **kwargs)\u001B[0m\n\u001B[1;32m    236\u001B[0m       \u001B[0minputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    237\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 238\u001B[0;31m     \u001B[0mnum_samples\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mnest\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mflatten\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    239\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnum_samples\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    240\u001B[0m       \u001B[0mmsg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"Data cardinality is ambiguous:\\n\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/ds/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/data_adapter.py\u001B[0m in \u001B[0;36m<genexpr>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    236\u001B[0m       \u001B[0minputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    237\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 238\u001B[0;31m     \u001B[0mnum_samples\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mnest\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mflatten\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    239\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnum_samples\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    240\u001B[0m       \u001B[0mmsg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"Data cardinality is ambiguous:\\n\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mIndexError\u001B[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "user_statement = input(\"Tell me something sarcastic: \\n\")\n",
    "data = tfidf.transform([user_statement]).toarray()\n",
    "output = model.predict(data)\n",
    "print(output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
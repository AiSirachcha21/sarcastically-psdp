{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "                                           utterance  speaker  \\\n0  It's just a privilege to watch your mind at work.  SHELDON   \n1  I don't think I'll be able to stop thinking ab...    PENNY   \n2  Since it's not bee season, you can have my epi...  SHELDON   \n3  Lois Lane is falling, accelerating at an initi...  SHELDON   \n4  I'm just inferring this is a couch because the...  SHELDON   \n\n                                             context  \\\n0  ['I never would have identified the fingerprin...   \n1  ['This is one of my favorite places to kick ba...   \n2  ['Here we go. Pad thai, no peanuts.', 'But doe...   \n3  ['A marathon? How many Superman movies are the...   \n4  [\"Great Caesar's ghost, look at this place.\", ...   \n\n                                    context_speakers show  sarcasm  \n0                             ['LEONARD', 'SHELDON']  BBT     True  \n1  ['HOWARD', 'PENNY', 'HOWARD', 'HOWARD', 'HOWAR...  BBT     True  \n2                   ['LEONARD', 'HOWARD', 'LEONARD']  BBT    False  \n3  ['PENNY', 'SHELDON', 'PENNY', 'SHELDON', 'SHEL...  BBT    False  \n4  ['SHELDON', 'LEONARD', 'SHELDON', 'SHELDON', '...  BBT     True  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>utterance</th>\n      <th>speaker</th>\n      <th>context</th>\n      <th>context_speakers</th>\n      <th>show</th>\n      <th>sarcasm</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>It's just a privilege to watch your mind at work.</td>\n      <td>SHELDON</td>\n      <td>['I never would have identified the fingerprin...</td>\n      <td>['LEONARD', 'SHELDON']</td>\n      <td>BBT</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>I don't think I'll be able to stop thinking ab...</td>\n      <td>PENNY</td>\n      <td>['This is one of my favorite places to kick ba...</td>\n      <td>['HOWARD', 'PENNY', 'HOWARD', 'HOWARD', 'HOWAR...</td>\n      <td>BBT</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Since it's not bee season, you can have my epi...</td>\n      <td>SHELDON</td>\n      <td>['Here we go. Pad thai, no peanuts.', 'But doe...</td>\n      <td>['LEONARD', 'HOWARD', 'LEONARD']</td>\n      <td>BBT</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Lois Lane is falling, accelerating at an initi...</td>\n      <td>SHELDON</td>\n      <td>['A marathon? How many Superman movies are the...</td>\n      <td>['PENNY', 'SHELDON', 'PENNY', 'SHELDON', 'SHEL...</td>\n      <td>BBT</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I'm just inferring this is a couch because the...</td>\n      <td>SHELDON</td>\n      <td>[\"Great Caesar's ghost, look at this place.\", ...</td>\n      <td>['SHELDON', 'LEONARD', 'SHELDON', 'SHELDON', '...</td>\n      <td>BBT</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('normalized_mustard_dataset.csv')\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "embedding_size = 16\n",
    "max_length = 60\n",
    "\n",
    "required_data = data[['utterance', 'sarcasm']]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "                                           utterance  speaker  \\\n0  It's just a privilege to watch your mind at work.  SHELDON   \n1  I don't think I'll be able to stop thinking ab...    PENNY   \n2  Since it's not bee season, you can have my epi...  SHELDON   \n3  Lois Lane is falling, accelerating at an initi...  SHELDON   \n4  I'm just inferring this is a couch because the...  SHELDON   \n\n                                             context  \\\n0  ['I never would have identified the fingerprin...   \n1  ['This is one of my favorite places to kick ba...   \n2  ['Here we go. Pad thai, no peanuts.', 'But doe...   \n3  ['A marathon? How many Superman movies are the...   \n4  [\"Great Caesar's ghost, look at this place.\", ...   \n\n                                    context_speakers show  sarcasm  \n0                             ['LEONARD', 'SHELDON']  BBT        1  \n1  ['HOWARD', 'PENNY', 'HOWARD', 'HOWARD', 'HOWAR...  BBT        1  \n2                   ['LEONARD', 'HOWARD', 'LEONARD']  BBT        0  \n3  ['PENNY', 'SHELDON', 'PENNY', 'SHELDON', 'SHEL...  BBT        0  \n4  ['SHELDON', 'LEONARD', 'SHELDON', 'SHELDON', '...  BBT        1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>utterance</th>\n      <th>speaker</th>\n      <th>context</th>\n      <th>context_speakers</th>\n      <th>show</th>\n      <th>sarcasm</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>It's just a privilege to watch your mind at work.</td>\n      <td>SHELDON</td>\n      <td>['I never would have identified the fingerprin...</td>\n      <td>['LEONARD', 'SHELDON']</td>\n      <td>BBT</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>I don't think I'll be able to stop thinking ab...</td>\n      <td>PENNY</td>\n      <td>['This is one of my favorite places to kick ba...</td>\n      <td>['HOWARD', 'PENNY', 'HOWARD', 'HOWARD', 'HOWAR...</td>\n      <td>BBT</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Since it's not bee season, you can have my epi...</td>\n      <td>SHELDON</td>\n      <td>['Here we go. Pad thai, no peanuts.', 'But doe...</td>\n      <td>['LEONARD', 'HOWARD', 'LEONARD']</td>\n      <td>BBT</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Lois Lane is falling, accelerating at an initi...</td>\n      <td>SHELDON</td>\n      <td>['A marathon? How many Superman movies are the...</td>\n      <td>['PENNY', 'SHELDON', 'PENNY', 'SHELDON', 'SHEL...</td>\n      <td>BBT</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I'm just inferring this is a couch because the...</td>\n      <td>SHELDON</td>\n      <td>[\"Great Caesar's ghost, look at this place.\", ...</td>\n      <td>['SHELDON', 'LEONARD', 'SHELDON', 'SHELDON', '...</td>\n      <td>BBT</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sarcasm'].replace({True:1,False:0},inplace=True)\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(data['utterance'].values)\n",
    "train = tokenizer.texts_to_sequences(data['utterance'].values)\n",
    "padded_train_sequences = pad_sequences(train, maxlen=max_length, padding='post')\n",
    "y_train = to_categorical(data['sarcasm'], num_classes=2)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(padded_train_sequences,y_train, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import codecs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "def load_fasttext_vectors2(fname):\n",
    "    embeddings_index = {}\n",
    "    f = codecs.open(fname, encoding='utf-8')\n",
    "    for line in tqdm(f):\n",
    "        values = line.rstrip().rsplit(' ')\n",
    "        ft_word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[ft_word] = coefs\n",
    "    f.close()\n",
    "    return embeddings_index"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999995it [01:28, 11283.37it/s]\n"
     ]
    }
   ],
   "source": [
    "w2v_model =  load_fasttext_vectors2(\"wiki-news-300d-1M.vec\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Flatten, LSTM, Bidirectional, Conv1D, MaxPooling1D, Input, Embedding\n",
    "from tensorflow.keras.models import Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "words_not_found = []\n",
    "nb_words = len(tokenizer.word_index)\n",
    "embedding_matrix = np.zeros((nb_words + 1, 300))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if i >= nb_words:\n",
    "        continue\n",
    "    embedding_vector = w2v_model.get(word)\n",
    "    if (embedding_vector is not None) and len(embedding_vector) > 0:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    else:\n",
    "        words_not_found.append(word)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "main_input (InputLayer)      [(None, 60)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_8 (Embedding)      (None, 60, 300)           610800    \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 57, 50)            60050     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 28, 50)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 26, 100)           15100     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 13, 100)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 13, 256)           234496    \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 3328)              0         \n",
      "_________________________________________________________________\n",
      "fully_connected (Dense)      (None, 100)               332900    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 1,253,548\n",
      "Trainable params: 642,748\n",
      "Non-trainable params: 610,800\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "input_data = Input(shape=(max_length,), name='main_input')\n",
    "embedding_layer = Embedding(vocab_size + 1, 300, weights=[embedding_matrix], trainable=False)(input_data)\n",
    "conv_1 = Conv1D(filters=50, kernel_size=4, activation='relu')(embedding_layer)\n",
    "max_1 = MaxPooling1D(pool_size=2)(conv_1)\n",
    "conv_2 = Conv1D(filters=100, kernel_size=3, activation='relu')(max_1)\n",
    "max_2 = MaxPooling1D(pool_size=2)(conv_2)\n",
    "\n",
    "lstm_layer = Bidirectional(LSTM(128,return_sequences=True))(max_2)\n",
    "\n",
    "flatten = Flatten()(lstm_layer)\n",
    "dense = Dense(100, activation='relu', name='fully_connected')(flatten)\n",
    "out = Dense(2, activation='softmax')(dense)\n",
    "\n",
    "model = Model(inputs=[input_data], outputs=[out])\n",
    "\n",
    "print(model.summary())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 552 samples\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-27 03:00:49.795291: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference___backward_standard_lstm_47618_48103_specialized_for_StatefulPartitionedCall_at___inference_distributed_function_48828' and '__inference___backward_cudnn_lstm_with_fallback_46815_46997' both implement 'lstm_5a046278-f3c2-45d3-b453-1b8327956995' but their signatures do not match.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "552/552 [==============================] - 5s 10ms/sample - loss: 0.6801 - accuracy: 0.6087\n",
      "Epoch 7/20\n",
      "552/552 [==============================] - 1s 2ms/sample - loss: 0.6736 - accuracy: 0.6105\n",
      "Epoch 8/20\n",
      "552/552 [==============================] - 1s 2ms/sample - loss: 0.6667 - accuracy: 0.6268\n",
      "Epoch 9/20\n",
      "552/552 [==============================] - 1s 2ms/sample - loss: 0.6630 - accuracy: 0.6304\n",
      "Epoch 10/20\n",
      "552/552 [==============================] - 1s 2ms/sample - loss: 0.6515 - accuracy: 0.6377\n",
      "Epoch 11/20\n",
      "552/552 [==============================] - 1s 2ms/sample - loss: 0.6325 - accuracy: 0.6884\n",
      "Epoch 12/20\n",
      "552/552 [==============================] - 1s 2ms/sample - loss: 0.6155 - accuracy: 0.7228\n",
      "Epoch 13/20\n",
      "552/552 [==============================] - 1s 2ms/sample - loss: 0.6004 - accuracy: 0.7029\n",
      "Epoch 14/20\n",
      "552/552 [==============================] - 1s 2ms/sample - loss: 0.5733 - accuracy: 0.7264\n",
      "Epoch 15/20\n",
      "552/552 [==============================] - 1s 2ms/sample - loss: 0.5323 - accuracy: 0.7717\n",
      "Epoch 16/20\n",
      "552/552 [==============================] - 1s 2ms/sample - loss: 0.4802 - accuracy: 0.8297\n",
      "Epoch 17/20\n",
      "552/552 [==============================] - 1s 2ms/sample - loss: 0.4191 - accuracy: 0.8623\n",
      "Epoch 18/20\n",
      "552/552 [==============================] - 1s 2ms/sample - loss: 0.3450 - accuracy: 0.8949\n",
      "Epoch 19/20\n",
      "552/552 [==============================] - 1s 2ms/sample - loss: 0.2670 - accuracy: 0.9257\n",
      "Epoch 20/20\n",
      "552/552 [==============================] - 1s 2ms/sample - loss: 0.1994 - accuracy: 0.9475\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(lr=0.0001), metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train,  batch_size=64, epochs=5, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-sarcastic\n",
      "[0.89285547 0.10714462]\n"
     ]
    }
   ],
   "source": [
    "user_statement = input(\"Tell me something sarcastic: \\n\")\n",
    "tokenized_statement = tokenizer.texts_to_sequences(user_statement)\n",
    "tokenized_statement = pad_sequences(tokenized_statement, maxlen=max_length)\n",
    "output = model.predict(tokenized_statement)[0]\n",
    "\n",
    "if np.argmax(output) == 0:\n",
    "    print(\"Non-sarcastic\")\n",
    "elif np.argmax(output) == 1:\n",
    "    print(\"Sarcasm\")\n",
    "print(output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "model.save(\"text-model.h5\", overwrite=True, save_format='h5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}